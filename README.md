# 100 Days of CUDA

## Introduction
Over the next 100 days, I will deepen my understanding of CUDA programming and GPU architectures—studying thread hierarchies, shared memory, and synchronization—while sharing learnings and code snippets. I will implement core ML primitives (matrix multiplication, activations, convolution layers) from scratch in CUDA C/C++, profiling and optimizing memory access and thread-block layouts, and explore warp-level operations, mixed-precision arithmetic, and profiling tools to build and fine-tune convolutional models on the GPU.
